# Task 008 â€” Camera â†’ Object Detection (YOLO)
Behavior Level â†’ Sensor Processing

This task performs object detection from a camera image stream using a YOLO-based processing node.

---

# ğŸ“¥ Input
- `/camera/image_raw` (sensor_msgs/Image)

# ğŸ“¤ Output
- `/detections` (custom or standard detection message)

---

# ğŸ“ Directory Structure
task_008_camera_object_detection_yolo/
â”‚â”€â”€ metadata.json  
â”‚â”€â”€ README.md  
â”‚â”€â”€ Dockerfile  
â”‚â”€â”€ setup.sh  
â”‚â”€â”€ ros1_code/
â”‚   â”œâ”€â”€ camera_subscriber.py       â† contains one TODO
â”‚   â”œâ”€â”€ yolo_detector_node.py      â† contains one TODO
â”‚   â””â”€â”€ launch/
â”‚       â””â”€â”€ yolo_detection.launch
â”‚â”€â”€ tests/

---

# ğŸ§© TODO Description

### 1. camera_subscriber.py  
Goal:  
Subscribe to `/camera/image_raw` and store/forward frames.

### 2. yolo_detector_node.py  
Goal:  
Process incoming camera frames and publish detection results.


---

# â­ Expected ROS2 Outcome (Brief)

A correct ROS2 solution should:

1. Use `rclpy` and `sensor_msgs.msg.Image`.
2. Subscribe to `/camera/image_raw` and convert using `cv_bridge`.
3. Run YOLO inference (OpenCV DNN or YOLOv5/YOLOX, etc.).
4. Publish detection results on `/detections`.
5. Use QoS profiles appropriate for sensor data.

---

# ğŸ³ Docker Usage

Build:
```docker build -t task008_yolo .
```

Run:

```
docker run -it --net=host task008_yolo
```

Inside container:

```
roslaunch task_008_camera_object_detection_yolo yolo_detection.launch
```
